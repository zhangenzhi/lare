experiment:
  context:
    name: multi_lare
    devices: 1
    log_path: ./log
    multi-p: 5

  main_loop:
    warmup: 
      student_nums: 0
      supervisor_iters: 1
    nums: 1
    student_nums: 1

  student:
    dataloader:
      name: cifar10 # default cifar10
      epochs: 100
      batch_size: 128
      da: False
    model:
      name: dnn # default dnn
      units: [128,64,32,10]
      activations: [relu,relu,relu,softmax]
    loss:
      name: CategoricalCrossentropy
    metrics: 
      name: CategoricalAccuracy
    optimizer:
      name: sgd # default SGD
      learning_rate: 0.1 # default 0.01
    train_loop:
        train:
          lr_decay: False
          online_update_sp: False
        valid:
          valid_gap: 100
          weight_space: sum_reduce
          online_update: False
        visual: False

  supervisor:
    dataloader:
      name: dnn_sumreduce
      exp: decay
      replay_window: 25
      batch_size: 128
      epochs: 100
    model:
      name: dnn # default dnn
      units: [128,64,32,1]
      activations: [relu,relu,relu,relu]
    optimizer:
      name: sgd
      learning_rate: 0.001
    loss:
      name: MeanSquaredError
    train_loop:
        valid:
          valid_gap: 100 